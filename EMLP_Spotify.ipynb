{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Popularitätsprognose von Spotify-Songs** | EMLP-Projekt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Link zum Datensatz](https://www.kaggle.com/yamaerenay/spotify-dataset-19212020-160k-tracks)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Einleitung\n",
    "Im Jahr 2020 ist Spotify mit mehr als 60 Millionen gelisteten Musiktiteln und über 320 Millionen aktiven Nutzern der größte Audio-Stremaing-Onlinedienst der Welt [https://www.spotify.com/]. Im Durchschnitt streamt jeder Nutzer pro Tag etwas mehr als eine Stunde Musik [https://de.statista.com/]. Damit ist klar, dass Spotify im Laufe der Zeit einen gigantischen Vorrat an Nutzungsdaten aufbauen konnte. Mit der Anzahl der Wiedergaben und einer Gewichtung, die berücksichtigt, wie lange die Wiedergaben in der Zeit zurückliegen, berechnet Spotify für jeden Track einen Popularity-Index, der auf einer Skala von 0 (unpopulär) bis 100 (populär) angibt, wie beliebt der Track bei den Nutzern ist.  <br>\n",
    "Über die Web API  [https://developer.spotify.com/documentation/web-api/] können Metadaten, einige Signalanalyse-Parameter, sowie der Popularity-Index der gelisteten Tracks abgerufen werden. Der vorliegenden Datensatz beinhaltet Daten zu mehr als 170 000 Tracks, die über die Web API gesammelt wurden.  <br>\n",
    "Im Rahmen des EMLP-Projektes soll untersucht werden, welche Faktoren die Popularität eines Tracks beeinflussen. Projektziel ist es, ein Regressions-Modell zu entwickeln, dass die Popularität eines Tracks auf Basis der im Datensatz erfassten Metadaten und Signalanalyse-Parametern möglichst genau vorhersagt. In diesem Projektbericht wird die Umsetzung der Datenanalyse mit Python detailliert beschrieben."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bibliotheken und Module"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Mit den nachfolgenden Befehlen werden die benötigten Bibliotheken und Module geladen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from sklearn import preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Erklärung zum Datensatz"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Der zu analysierende Datensatz ist wie folgt aufgebaut: Über eine Unique-ID 'id' ist jeder Track eindeutig identifizerbar. Die kategorischen Metadaten 'name' (Songtitel) und 'artist' (Künstler) geben an, um welchen Track es handelt. Das Erscheinungsjahr und das Erscheinungsdatum sind in 'year' und 'release_date' kodiert. Neben dem Popularity-Index 'popularity', der die Beliebtheit des Tracks quantifiziert, enthält der Datensatz weitere numerische Parameter 'valence', 'acousticness', 'dancability', 'energy', 'instrumentalness', 'liveness', 'loudness', 'speechiness' und 'tempo', die über Signalanalysealgorithmen berechnet wurden. Diese Parameter charakterisieren die psychoakustischen Eigenschaften der Tracks. Darüber hinaus enthält der Datensatz die binären Daten 'mode' (0: Moll/1: Dur) und 'explicit' (0: jugendfrei/1: nicht jugendfrei) sowie die kategorischen Daten 'key' (Tonart). \n",
    "In der nachfolgenden Tabelle sind alle im Datensatz enthaltenen Werte, ihr Datentyp, sowie eine detaillierte Beschreibung aufgelistet."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<table>\n",
    "  <thead>\n",
    "    <tr>\n",
    "      <th>Key</th>\n",
    "      <th>Value Type</th>\n",
    "      <th>Value Description</th>\n",
    "    </tr>\n",
    "  </thead>\n",
    "  <tbody>\n",
    "    <tr>\n",
    "      <td>popularity</td>\n",
    "      <td>int</td>\n",
    "      <td>Popularity is based on (1) the total number of plays compared to other tracks and (2) how recent those plays are.</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <td>valence</td>\n",
    "      <td>float</td>\n",
    "      <td>A measure from 0.0 to 1.0 describing the musical positiveness conveyed by a track. Tracks with high valence sound more positive (e.g. happy, cheerful, euphoric), while tracks with low valence sound more negative (e.g. sad, depressed, angry).</td>  \n",
    "    </tr>\n",
    "    <tr>\n",
    "      <td>year</td>\n",
    "      <td>int</td>\n",
    "      <td>The release year of track.</td>  \n",
    "    </tr>\n",
    "    <tr>\n",
    "      <td>acousticness</td>\n",
    "      <td>float</td>\n",
    "      <td>\tA confidence measure from 0.0 to 1.0 of whether the track is acoustic. 1.0 represents high confidence the track is acoustic.</td>  \n",
    "    </tr>\n",
    "    <tr>\n",
    "      <td>artists</td>\n",
    "      <td>float</td>\n",
    "      <td>The list of artists credited for production of the track.</td>  \n",
    "    </tr>\n",
    "    <tr>\n",
    "      <td>dancability</td>\n",
    "      <td>float</td>\n",
    "      <td>Danceability describes how suitable a track is for dancing based on a combination of musical elements including tempo, rhythm stability, beat strength, and overall regularity. A value of 0.0 is least danceable and 1.0 is most danceable.</td>  \n",
    "    </tr>\n",
    "    <tr>\n",
    "      <td>duration_ms</td>\n",
    "      <td>int</td>\n",
    "      <td>The duration of the track in milliseconds.</td>  \n",
    "    </tr>\n",
    "    <tr>\n",
    "      <td>energy</td>\n",
    "      <td>float</td>\n",
    "      <td>Energy is a measure from 0.0 to 1.0 and represents a perceptual measure of intensity and activity. Typically, energetic tracks feel fast, loud, and noisy. For example, death metal has high energy, while a Bach prelude scores low on the scale. Perceptual features contributing to this attribute include dynamic range, perceived loudness, timbre, onset rate, and general entropy.</td>  \n",
    "    </tr>\n",
    "    <tr>\n",
    "      <td>explicit</td>\n",
    "      <td>int</td>\n",
    "      <td>The binary value whether the track contains explicit content or not.</td>  \n",
    "    </tr>\n",
    "    <tr>\n",
    "      <td>id</td>\n",
    "      <td>string</td>\n",
    "      <td>The Spotify ID for the track.</td>  \n",
    "    </tr>\n",
    "    <tr>\n",
    "      <td>instrumentalness</td>\n",
    "      <td>float</td>\n",
    "      <td>Predicts whether a track contains no vocals. “Ooh” and “aah” sounds are treated as instrumental in this context. Rap or spoken word tracks are clearly “vocal”. The closer the instrumentalness value is to 1.0, the greater likelihood the track contains no vocal content. Values above 0.5 are intended to represent instrumental tracks, but confidence is higher as the value approaches 1.0.</td>  \n",
    "    </tr>\n",
    "    <tr>\n",
    "      <td>key</td>\n",
    "      <td>int</td>\n",
    "      <td>The estimated overall key of the track. Integers map to pitches using standard Pitch Class notation as integers in between 0 and 11. E.g. 0 = C, 1 = C♯/D♭, 2 = D, and so on. If no key was detected, the value is -1.</td>  \n",
    "    </tr>\n",
    "    <tr>\n",
    "      <td>liveness</td>\n",
    "      <td>float</td>\n",
    "      <td>Detects the presence of an audience in the recording. Higher liveness values represent an increased probability that the track was performed live. A value above 0.8 provides strong likelihood that the track is live.</td>  \n",
    "    </tr>\n",
    "    <tr>\n",
    "      <td>loudness</td>\n",
    "      <td>float</td>\n",
    "      <td>The overall loudness of a track in decibels (dB). Loudness values are averaged across the entire track and are useful for comparing relative loudness of tracks. Loudness is the quality of a sound that is the primary psychological correlate of physical strength (amplitude). Values typical range between -60 and 0 db. </td>  \n",
    "    </tr>\n",
    "    <tr>\n",
    "      <td>mode</td>\n",
    "      <td>int</td>\n",
    "      <td>The binary value representing whether the track starts with a major (1) chord progression or not (0).</td>  \n",
    "    </tr>\n",
    "    <tr>\n",
    "      <td>name</td>\n",
    "      <td>string</td>\n",
    "      <td>The name of the track.</td>  \n",
    "    </tr>\n",
    "    <tr>\n",
    "      <td>release_date</td>\n",
    "      <td>string</td>\n",
    "      <td>The date of release of the track in yyyy-mm-dd, yyyy-mm, or even yyyy format.</td>  \n",
    "    </tr>\n",
    "    <tr>\n",
    "      <td>speachiness</td>\n",
    "      <td>float</td>\n",
    "      <td>\tSpeechiness detects the presence of spoken words in a track. The more exclusively speech-like the recording (e.g. talk show, audio book, poetry), the closer to 1.0 the attribute value. Values above 0.66 describe tracks that are probably made entirely of spoken words. Values between 0.33 and 0.66 describe tracks that may contain both music and speech, either in sections or layered, including such cases as rap music. Values below 0.33 most likely represent music and other non-speech-like tracks.</td>  \n",
    "    </tr>\n",
    "    <tr>\n",
    "      <td>tempo</td>\n",
    "      <td>int</td>\n",
    "      <td>The overall estimated tempo of a track in beats per minute (BPM). In musical terminology, tempo is the speed or pace of a given piece and derives directly from the average beat duration.</td>  \n",
    "    </tr>   \n",
    "  </tbody>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Datenimport"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Um die 25 MB Grenze von GitHub zu umgehen, musste die originale CSV-Datei 'data.csv' in zwei Teile gesplittet werden. Hierfür wurde der folgende Code verwendet:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df = pd.read_csv('data.csv')\n",
    "#df1 = df[0:85273]\n",
    "#df2 = df[85273:]\n",
    "#df1.to_csv(\"data1.csv\", header=list(df1), index=False)\n",
    "#df2.to_csv(\"data2.csv\", header=list(df2), index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Mit diesen Zeilen werden die gesplitteten Daten importiert und wieder zu einem DataFrame zusammengefügt:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = pd.read_csv('data1.csv') # Einlesen der Daten aus CSV-Datei\n",
    "df2 = pd.read_csv('data2.csv') # Einlesen der Daten aus CSV-Datei\n",
    "df = pd.concat([df1,df2], ignore_index = True) # Vertikales Verbinden der beiden DataFrames"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Erste Untersuchung des Datensatzes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Mit den folgenden Zeilen Code werden grundlegende Informationen zum Datensatz wie zum Beispiel Anzahl der Einträge oder Datentypen untersucht. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 170653 entries, 0 to 170652\n",
      "Data columns (total 19 columns):\n",
      " #   Column            Non-Null Count   Dtype  \n",
      "---  ------            --------------   -----  \n",
      " 0   valence           170653 non-null  float64\n",
      " 1   year              170653 non-null  int64  \n",
      " 2   acousticness      170653 non-null  float64\n",
      " 3   artists           170653 non-null  object \n",
      " 4   danceability      170653 non-null  float64\n",
      " 5   duration_ms       170653 non-null  int64  \n",
      " 6   energy            170653 non-null  float64\n",
      " 7   explicit          170653 non-null  int64  \n",
      " 8   id                170653 non-null  object \n",
      " 9   instrumentalness  170653 non-null  float64\n",
      " 10  key               170653 non-null  int64  \n",
      " 11  liveness          170653 non-null  float64\n",
      " 12  loudness          170653 non-null  float64\n",
      " 13  mode              170653 non-null  int64  \n",
      " 14  name              170653 non-null  object \n",
      " 15  popularity        170653 non-null  int64  \n",
      " 16  release_date      170653 non-null  object \n",
      " 17  speechiness       170653 non-null  float64\n",
      " 18  tempo             170653 non-null  float64\n",
      "dtypes: float64(9), int64(6), object(4)\n",
      "memory usage: 24.7+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info() # Allgemeine Infos zum Datensatz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df.head() # Die ersten 5 Einträge werden ausgegeben"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df.tail() # Die letzten 5 Einträge werden ausgegeben"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df.describe() # Einige statistische Infos zum Datensatz (Mittelwert, Quantile, ...)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bereinigung des Datensatzes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Mit den folgenden Code-Zeilen werden die Werte der Spalte 'duration_ms' in Minuten umgerechnet, was die Verständlichkeit fördert. Tracks mit mehr als 12 min Dauer werden aus dem Datensatz entfernt, da es sich bei diesen mit großer Wahrscheinlichkeit um Hörbücher/Podcasts/Live-Aufnahmen handelt und nicht um Songs. Zudem wird der Datensatz auf Doubletten und 0/NaN-Werte untersucht. Die Spalten 'release_date' und 'id' werden entfernt, da sie keine sinnvollen Informationen beitragen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.duration_ms = df.duration_ms/60000 # Umrechnung von ms in min\n",
    "df = df.rename(columns={'duration_ms' : 'duration_min'}) # Umbenennen der Spalte 'duration_ms' in 'duration_min'\n",
    "df = pd.DataFrame(df[df['duration_min'] < 12]) # Behalte alle Tracks mit <= 12 min Dauer\n",
    "#df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Der Datensatz enthält 0 Doubletten.\n"
     ]
    }
   ],
   "source": [
    "n_doubletten = df.duplicated(subset = None, keep = 'first').sum() # Test auf doppelte Einträge\n",
    "print(f'Der Datensatz enthält {n_doubletten} Doubletten.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Der Datensatz enthält 0 NaN-Werte.\n"
     ]
    }
   ],
   "source": [
    "n_isnan = df.isnull().sum().sum() # Test auf NaN-Einträge\n",
    "print(f'Der Datensatz enthält {n_isnan} NaN-Werte.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop(labels = ['release_date', 'id'], axis = 1) # 'Release_date' ist in unerschiedlicher Genauigkeit angegeben und doppelt sich mit 'year' -> drop!\n",
    "# 'id' wird ebenfalls gedroppt, da uninformativ"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split in numerische Daten und String-Daten"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Der Datensatz wird für die weiteren Untersuchungen in numerische Daten und String-Daten aufgeteilt."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_str = pd.DataFrame(data = df, columns = df.columns[df.dtypes == 'object'], index = df.index) # neuer df mit String-Daten\n",
    "df_num = pd.DataFrame(data = df, columns = df.columns[df.dtypes != 'object'], index = df.index) # neuer df mit numerischen Daten"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Normalisierung der numerischen Daten"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Damit in den Machine-Learning-Modellen alle Features mit der selben Gewichtung eingehen, werden die numerischen Daten auf das Intervall [0, 1] normalisiert. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = df_num.values # Gibt Daten als NumPy-Array zurück\n",
    "min_max_scaler = preprocessing.MinMaxScaler()\n",
    "x_scaled = min_max_scaler.fit_transform(x) # [0, 1]-Normalisierung mit Sklearn\n",
    "df_num = pd.DataFrame(x_scaled, columns = df_num.columns, index = df_num.index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Datenvisualisierung"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Im Folgenden werden die Daten des Spotify-Datensatzes visualisiert, um erste qualitative Zusammenhänge zu untersuchen."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Histogramme"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# g = df_num.hist(figsize = (15, 15), color = '#1DB954', ec = \"black\") # Zeigt die Verteilung der Werte; #1DB954 für Spotify-Grün\n",
    "# plt.suptitle('Histogramme')\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Auffälligkeiten:\n",
    "- 'valence', 'year' und 'energy' sind in etwa gleichverteilt\n",
    "- 'dancability', 'duration', 'loudness' und 'tempo' sind ungefähr normalverteilt\n",
    "- 'acousticness', 'instrumentalness', 'explicit' und 'mode' zeigen eine stark zweiseitige Verteilung\n",
    "- 'speechiness' ist für fast alle Tracks sehr niedrig"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pairplot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.figure(figsize = (25, 25))\n",
    "# g = sns.pairplot(df_num.sample(1000), hue = 'popularity', kind = 'reg', plot_kws = {'line_kws':{'color':'red'}, 'scatter_kws': {'color':'#1DB954','alpha': 0.05}}, diag_kws = {'color':'#1DB954'})\n",
    "# g.fig.suptitle('Pairplot')\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Korrelationsmatrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.figure(figsize = (15, 15))\n",
    "# ax = plt.axes()\n",
    "# sns.heatmap(df_num.corr(), annot = True, cmap = 'PiYG', ax = ax)\n",
    "# ax.set_title('Korrelationskoeffizienten (Pearson)')\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Auffälligkeiten:\n",
    "- 'year' (r = +0.86), 'energy' (r = +0.48) und 'loudness' (r = +0.46) haben die stärkste positive Korrelation mit der 'popularity'\n",
    "- 'acousticness (r = -0.57), 'instrumentalness' (r = -0.29) und speechiness (r = -0.17) haben die stärkste negative Korrelation mit der 'popularity'\n",
    "\n",
    "Fazit: Je aktueller, und energiegeladener (Tempo/Lautstärke/...) ein Track ist, desto populärer ist er. Je größer der Anteil an akustischen Instrumenten oder Sprache (nicht Gesang) ist, desto unpopulärer ist ein Track."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## String-Daten: Target Encoding (Schlechte Idee?)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Die String-Daten 'artist' und 'name' können nicht direkt für das Machine Learning verwendet werden, da es sich nicht um numerische Daten handelt. In diesem Kapitel werden die Daten daher mit einem Target-Encoding in numerische Daten umgewandelt. Die 'artist'-Werte werden mit der mittleren Popularität der Tracks eines Künstlers ('artist_popularity) ersetzt, die 'name'-Strings werden aufgeteilt in einzelne Wörter, für die jeweils die mittlere Popularität berechnet wird. Auf Basis dieser Werte wird ein Titel Popularity-Index für jeden Track zusammengesetzt. <br>\n",
    "Die Vorgehensweise ist nicht unproblematisch, da durch das Target Encoding die Input- und Target-Daten statistisch voneinander abhängig gemacht werden. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Künstler Popularity-Index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_art = pd.concat([df_str['artists'], df_num['popularity']], axis = 1) # Neuer df mit artist und popularity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_art['popularity'] = df_art['popularity'].groupby([df_art['artists']]).transform('mean') # Ersetzen der popularity mit mittlerer popularity des artist\n",
    "df_art = df_art.rename(columns={'popularity' : 'artists_popularity'}) # Umbenennen der Spalte 'popularity' in 'artist_popularity'\n",
    "df_art = pd.concat([df_art, df_num['popularity']], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_art.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.figure(figsize=(15, 15))\n",
    "# g = sns.pairplot(frame.sample(1000), kind = 'reg', plot_kws={'line_kws':{'color':'red'}, 'scatter_kws': {'color':'#1DB954','alpha': 0.05}}, diag_kws={'color':'#1DB954'})\n",
    "# g.fig.suptitle('Pairplot')\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>artists</th>\n",
       "      <th>artists_popularity</th>\n",
       "      <th>popularity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>19611</th>\n",
       "      <td>['Bad Bunny', 'Jhay Cortez']</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19606</th>\n",
       "      <td>['24kGoldn', 'iann dior']</td>\n",
       "      <td>0.99</td>\n",
       "      <td>0.99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19608</th>\n",
       "      <td>['Cardi B', 'Megan Thee Stallion']</td>\n",
       "      <td>0.96</td>\n",
       "      <td>0.96</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19620</th>\n",
       "      <td>['Justin Bieber', 'benny blanco']</td>\n",
       "      <td>0.95</td>\n",
       "      <td>0.95</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19720</th>\n",
       "      <td>['Sech', 'Daddy Yankee', 'J Balvin', 'ROSALÍA'...</td>\n",
       "      <td>0.94</td>\n",
       "      <td>0.94</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19655</th>\n",
       "      <td>['Joel Corry', 'MNEK']</td>\n",
       "      <td>0.94</td>\n",
       "      <td>0.94</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19609</th>\n",
       "      <td>['Drake', 'Lil Durk']</td>\n",
       "      <td>0.93</td>\n",
       "      <td>0.93</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19621</th>\n",
       "      <td>['Ritt Momney']</td>\n",
       "      <td>0.93</td>\n",
       "      <td>0.93</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19672</th>\n",
       "      <td>['J Balvin', 'Tainy', 'Dua Lipa', 'Bad Bunny']</td>\n",
       "      <td>0.92</td>\n",
       "      <td>0.92</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38452</th>\n",
       "      <td>['Manuel Turizo', 'Rauw Alejandro', 'Myke Towe...</td>\n",
       "      <td>0.92</td>\n",
       "      <td>0.92</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38427</th>\n",
       "      <td>['Jay Wheeler', 'DJ Nelson', 'Myke Towers']</td>\n",
       "      <td>0.92</td>\n",
       "      <td>0.92</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19426</th>\n",
       "      <td>['Topic', 'A7S']</td>\n",
       "      <td>0.92</td>\n",
       "      <td>0.92</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38426</th>\n",
       "      <td>['Lele Pons', 'Guaynaa']</td>\n",
       "      <td>0.92</td>\n",
       "      <td>0.92</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57360</th>\n",
       "      <td>['Justin Quiles']</td>\n",
       "      <td>0.91</td>\n",
       "      <td>0.91</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38492</th>\n",
       "      <td>['Ozuna', 'J Balvin', 'Chencho Corleone']</td>\n",
       "      <td>0.91</td>\n",
       "      <td>0.91</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 artists  artists_popularity  \\\n",
       "19611                       ['Bad Bunny', 'Jhay Cortez']                1.00   \n",
       "19606                          ['24kGoldn', 'iann dior']                0.99   \n",
       "19608                 ['Cardi B', 'Megan Thee Stallion']                0.96   \n",
       "19620                  ['Justin Bieber', 'benny blanco']                0.95   \n",
       "19720  ['Sech', 'Daddy Yankee', 'J Balvin', 'ROSALÍA'...                0.94   \n",
       "19655                             ['Joel Corry', 'MNEK']                0.94   \n",
       "19609                              ['Drake', 'Lil Durk']                0.93   \n",
       "19621                                    ['Ritt Momney']                0.93   \n",
       "19672     ['J Balvin', 'Tainy', 'Dua Lipa', 'Bad Bunny']                0.92   \n",
       "38452  ['Manuel Turizo', 'Rauw Alejandro', 'Myke Towe...                0.92   \n",
       "38427        ['Jay Wheeler', 'DJ Nelson', 'Myke Towers']                0.92   \n",
       "19426                                   ['Topic', 'A7S']                0.92   \n",
       "38426                           ['Lele Pons', 'Guaynaa']                0.92   \n",
       "57360                                  ['Justin Quiles']                0.91   \n",
       "38492          ['Ozuna', 'J Balvin', 'Chencho Corleone']                0.91   \n",
       "\n",
       "       popularity  \n",
       "19611        1.00  \n",
       "19606        0.99  \n",
       "19608        0.96  \n",
       "19620        0.95  \n",
       "19720        0.94  \n",
       "19655        0.94  \n",
       "19609        0.93  \n",
       "19621        0.93  \n",
       "19672        0.92  \n",
       "38452        0.92  \n",
       "38427        0.92  \n",
       "19426        0.92  \n",
       "38426        0.92  \n",
       "57360        0.91  \n",
       "38492        0.91  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_art.sort_values(by = 'artists_popularity', ascending = False).head(n = 15)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Auffälligkeiten: Kollaborationen pushen die Popularität. \"Bad Bunny x Jhay Cortez\", \"24kGoldn x Iann Dior\", \"Cardi B x Megan Thee Stallion\", \"Justin Bieber x Benni Blanco\" und \"Sech x Daddy Yankee x J Balvin x Rosalía Farruko\" sind die 5 populärsten Kollabs. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Titel Popularity-Index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_nam = pd.concat([df_str['name'], df_num['popularity']], axis = 1) # Neuer df mit name und popularity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_nam['name'] = df_nam.name.astype(str)\n",
    "df_nam = df_nam.assign(name = df_nam.name.str.split()) # name-String wird anhand von Leerzeichen in Liste getrennt\n",
    "df_nam['name'] = df_nam['name'].map(lambda a: tuple(a))\n",
    "#df_nam.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_par = df_nam.explode('name') # Auftrennen des df_nam in einzelne name-Bestandteile und zugehöriger popularity\n",
    "#df_par.head(n=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_par['popularity'] = df_par['popularity'].groupby([df_par['name']]).transform('mean') # Ersetzen der popularity mit mittlerer popularity des name-Bestandteil\n",
    "df_par = df_par.assign(count = df_par['popularity'].groupby([df_par['name']]).transform('count')) # Zähle Erscheinungen des Namensbestandteils\n",
    "df_par = df_par.rename(columns={'popularity' : 'name_part_popularity'}) # Umbenennen der Spalte 'popularity' in 'name_part_popularity'\n",
    "df_par = df_par.drop_duplicates(subset='name')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>name_part_popularity</th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>19611</th>\n",
       "      <td>Dakiti</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19608</th>\n",
       "      <td>WAP</td>\n",
       "      <td>0.96</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19620</th>\n",
       "      <td>benny</td>\n",
       "      <td>0.95</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19620</th>\n",
       "      <td>blanco)</td>\n",
       "      <td>0.95</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19623</th>\n",
       "      <td>broke</td>\n",
       "      <td>0.95</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19655</th>\n",
       "      <td>MNEK)</td>\n",
       "      <td>0.94</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19624</th>\n",
       "      <td>Therefore</td>\n",
       "      <td>0.93</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19672</th>\n",
       "      <td>DIA</td>\n",
       "      <td>0.92</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19672</th>\n",
       "      <td>(ONE</td>\n",
       "      <td>0.92</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19672</th>\n",
       "      <td>DAY)</td>\n",
       "      <td>0.92</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            name  name_part_popularity  count\n",
       "19611     Dakiti                  1.00      1\n",
       "19608        WAP                  0.96      1\n",
       "19620      benny                  0.95      1\n",
       "19620    blanco)                  0.95      1\n",
       "19623      broke                  0.95      1\n",
       "19655      MNEK)                  0.94      1\n",
       "19624  Therefore                  0.93      1\n",
       "19672        DIA                  0.92      1\n",
       "19672       (ONE                  0.92      1\n",
       "19672       DAY)                  0.92      1"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_par.sort_values(by = 'name_part_popularity', ascending = False).head(n = 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Auffälligkeiten: Titel von populären Tracks (\"Dakiti\") und Namensbestandteile von populären Künstlern \"WAP\", \"Benny\", \"Blanco\"... führen das Ranking der Popularität von Titel-Bestandteilen an. \"Broke\", \"day\", \"dia\" und \"popstar\" sind ebenfalls prominente Bestandteile. Problem: einzigartige Titel, werden bei dieser Berechnungsmethode überbewertet, da keinerlei statistische Mittelung stattfindet -> Count-Value wird mit einbezogen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_par['name_part_popularity'] = 0.6*df_par['name_part_popularity']+0.4*df_par['count']/max(df_par['count']) # Count-Value wird berücksichtigt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_par.sort_values(by = 'name_part_popularity', ascending = False).head(n = 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hier wird der Titel-Popularitätsindex berechnet und in ein Excel-File exportiert, dass schnell importiert werden kann (Berechnung dauert ca. 2h!)\n",
    "#def name_popularity(x, df_nam, df_par):\n",
    "#    pop = 0\n",
    "#    n = 0\n",
    "#    for part in x:\n",
    "#        pop = pop + df_par['name_part_popularity'][df_par['name'] == part].values\n",
    "#        n += 1\n",
    "#    return str(pop/n)   \n",
    "#\n",
    "#df_nam['name'] = df_nam['name'].apply(lambda x: name_popularity(x, df_nam, df_par))\n",
    "#df_nam.to_excel(\"title_popularity.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_nam = pd.read_excel(\"title_popularity.xlsx\") # vor Re-Import Klammern [ und ] in Excel entfernen!\n",
    "df_nam = df_nam.rename(columns={'name' : 'title_popularity'})\n",
    "df_namscaled = df_nam['title_popularity']\n",
    "x = df_namscaled.values.reshape(-1, 1) # Gibt Daten als NumPy-Array zurück\n",
    "min_max_scaler = preprocessing.MinMaxScaler()\n",
    "x_scaled = min_max_scaler.fit_transform(x) # [0, 1]-Normalisierung mit Sklearn\n",
    "df_namscaled = pd.DataFrame(data=x_scaled, index=df_nam.index, columns=['title_popularity'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_num = df_num.reset_index(drop=True)\n",
    "df_namscaled = df_namscaled.reset_index(drop=True)\n",
    "df_art = df_art.reset_index(drop=True)\n",
    "df_prepro = pd.concat([df_num, df_namscaled, df_art['artists_popularity']], axis = 1)\n",
    "#df_prepro.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plt.figure(figsize = (15, 15))\n",
    "#ax = plt.axes()\n",
    "#sns.heatmap(df_prepro[['title_popularity', 'artists_popularity', 'popularity']].corr(), annot = True, cmap = 'PiYG', ax = ax)\n",
    "#ax.set_title('Korrelationskoeffizienten (Pearson)')\n",
    "#plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Auffälligkeiten: Vor allem der 'artists_popularity'-Wert korreliert stark mit der 'popularity', aber auch mit der 'title_popularity' gibt es eine starke Korrelation. Das zeigt, das der Künstler selbst, aber auch der Titel einen Einfluss auf die Popularität eines Tracks haben. Für die nachfolgenden Machine Learning Modelle werden die beiden Werte nicht verwendet, das sie auf Basis der Popularität berechnet wurden und somit die Target-Daten indirekt schon in den Trainingsdaten gegeben wären. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Machine Learning Modelle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Der Datensatz df_prepro enthält nur noch normalisierte numerische Daten, mit denen die Machine Learning Modelle trainiert werden können."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lineare Regression, Polynomische Regression, KNeighbors Regression, Ensemble und SVR im Vergleich"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bibliotheken"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression, LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn import svm\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.model_selection import train_test_split, RandomizedSearchCV\n",
    "from sklearn.metrics import mean_squared_error, r2_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Daten als NumPy-Array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import data\n",
    "X = np.array(df_prepro.drop(['popularity', 'artists_popularity', 'title_popularity'], axis=1)) # Input-Daten\n",
    "y = np.array(df_prepro['popularity']) # Target-Daten"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split in Trainings- und Testdaten"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, train_size = 0.6, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Print-Funktion 'print_scores' für Evaluation der Vorhersagen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Funktion für die Evaluation der Vorhersagen\n",
    "def print_metrics(y_true, preds, model_name=None):\n",
    "    \n",
    "    if model_name == None:\n",
    "        print('RMSE: ', format(np.sqrt(mean_squared_error(y_true, preds))))\n",
    "        print('R-Squared: ', format(r2_score(y_true, preds)))\n",
    "        #print('\\n\\n')\n",
    "    \n",
    "    else:\n",
    "        print('RSME für ' + model_name + ' :' , format(np.sqrt(mean_squared_error(y_true, preds))))\n",
    "        print('R-Squared für ' + model_name + ' :', format(r2_score(y_true, preds)))\n",
    "        #print('\\n\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multiple lineare Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RSME für Multiple Lineare Regression : 0.10736950441011192\n",
      "R-Squared für Multiple Lineare Regression : 0.7578720922895226\n"
     ]
    }
   ],
   "source": [
    "# Fit des linearen Regressionsmodells\n",
    "mlinear_regression = LinearRegression()\n",
    "mlinear_regression.fit(X_train,y_train)\n",
    "predictions = mlinear_regression.predict(X_test)\n",
    "print_metrics(y_test, predictions, model_name = 'Multiple Lineare Regression')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Coefficient</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>valence</th>\n",
       "      <td>0.005588</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>year</th>\n",
       "      <td>0.659581</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>acousticness</th>\n",
       "      <td>-0.042305</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>danceability</th>\n",
       "      <td>0.025414</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>duration_min</th>\n",
       "      <td>-0.001225</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>energy</th>\n",
       "      <td>-0.017828</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>explicit</th>\n",
       "      <td>0.009545</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>instrumentalness</th>\n",
       "      <td>-0.041919</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>key</th>\n",
       "      <td>0.000509</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>liveness</th>\n",
       "      <td>-0.028778</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>loudness</th>\n",
       "      <td>0.011226</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mode</th>\n",
       "      <td>-0.002704</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>speechiness</th>\n",
       "      <td>-0.076750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tempo</th>\n",
       "      <td>0.003225</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  Coefficient\n",
       "valence              0.005588\n",
       "year                 0.659581\n",
       "acousticness        -0.042305\n",
       "danceability         0.025414\n",
       "duration_min        -0.001225\n",
       "energy              -0.017828\n",
       "explicit             0.009545\n",
       "instrumentalness    -0.041919\n",
       "key                  0.000509\n",
       "liveness            -0.028778\n",
       "loudness             0.011226\n",
       "mode                -0.002704\n",
       "speechiness         -0.076750\n",
       "tempo                0.003225"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Ausgabe der Fit-Koeffizienten a*valence+b*year+c*acousticness...\n",
    "coeff_df = pd.DataFrame(mlinear_regression.coef_, df_prepro.drop(['popularity','artists_popularity', 'title_popularity'], axis=1).columns, columns=['Coefficient'])\n",
    "coeff_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Das recht simple multiple lineare Regressionsmodell approximiert die Test-Daten bereits sehr gut: RSME 0.11, R-Squared 0.76."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Polynomische Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Erstellung der polynomichen Features\n",
    "poly_feat = PolynomialFeatures(degree = 5)\n",
    "X_poly_train = poly_feat.fit_transform(X_train)\n",
    "X_poly_test = poly_feat.fit_transform(X_test)\n",
    "# Fit des linearen Regressionsmodells mit polynomischen Features\n",
    "poly_regression = LinearRegression()\n",
    "poly_regression.fit(X_poly_train,y_train)\n",
    "predictions = poly_regression.predict(X_poly_test)\n",
    "print_metrics(y_test, predictions, model_name = 'Polynomische Regression')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Polynomische Regression sehr rechenaufwändig für Ordnungen > 2 und führt zu schlechten Ergebnissen: RSME 70.21, R-Squared -105388.94 für n=5."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## KNeighbors Regression (mit RandomizedSearchCV)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RSME für KNeighbours Regression : 0.10618259168842684\n",
      "R-Squared für KNeighbours Regression : 0.7631956942395197\n"
     ]
    }
   ],
   "source": [
    "knnr = KNeighborsRegressor()\n",
    "#knnr.get_params()\n",
    "param_dist = {'n_neighbors': [5, 10, 15, 30]}\n",
    "              #,'weights': ['uniform','distance']} # Distance hat sich bewährt!\n",
    "knnr_search = RandomizedSearchCV(knnr, param_distributions = param_dist, n_iter = 4)\n",
    "knnr_search.fit(X_train,y_train)\n",
    "predictions = knnr_search.best_estimator_.predict(X_test)\n",
    "print_metrics(y_test, predictions, model_name = 'KNeighbours Regression')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'n_neighbors': 30}"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "knnr_search.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Das KNeigbors Regressions-Modell liefert gerundet die selbe Vorhersagegenauigkeit, wie das lineare Regressionsmodell: RSME 0.11\n",
    "R-Squared für KNeighbours Regression : 0.76. Die Genauigkeit wächst mit der Anzahl der Nachbarn, allerdings ist der Zuwachs ab n = 5 nicht sehr groß."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Support Vector Machine (mit RandomizedSearchCV)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "svr = svm.SVR()\n",
    "#svr.get_params()\n",
    "param_dist = {\"C\": [0.1, 0.5, 1, 3, 5],\n",
    "              \"kernel\": ['linear', 'poly', 'rbf', 'sigmoid']}\n",
    "svr_search = RandomizedSearchCV(svr, param_distributions = param_dist, n_iter = 8)\n",
    "svr_search.fit(X_train,y_train)\n",
    "predictions = svr_search.best_estimator_.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'kernel': 'rbf', 'C': 1}"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svr_search.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RSME für SVR,kernel:rpf,C:1 : 0.10152465386793308\n",
      "R-Squared für SVR,kernel:rpf,C:1 : 0.7835159086174623\n"
     ]
    }
   ],
   "source": [
    "print_metrics(y_test, predictions, model_name = 'SVR,kernel:rpf,C:1')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bis jetzt ist das SVR-Modell mit radial basis function kernel (rpf) das beste Modell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
